{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling for Data B (v.1.0)\n",
    "\n",
    "Brief description of the notebook\n",
    "\n",
    "# Goal\n",
    "\n",
    "Goal of the notebook\n",
    "\n",
    "# Plan\n",
    "\n",
    "Checklist what will be done on the notebook :\n",
    "\n",
    "    [ ] Get Data\n",
    "    [ ] \n",
    "\n",
    "# Summary\n",
    "\n",
    "Summary result of the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as utils_data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH=\"../data/raw/\"\n",
    "INTERIM_PATH=\"../data/interim/\"\n",
    "PROCESSED_PATH=\"../data/processed/\"\n",
    "MODEL_PATH=\"../models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alamhanz/anaconda/envs/word_s/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "data_raw=pd.read_csv(PROCESSED_PATH+'20190902_data_clean_B.csv')\n",
    "wv = KeyedVectors.load(MODEL_PATH+\"embedding_B.wv\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embbed(w):\n",
    "    vec=([0.0]*wv.vector_size)\n",
    "    try:\n",
    "        vec=wv[w].tolist()\n",
    "    except:\n",
    "        pass\n",
    "    return np.array(vec)\n",
    "\n",
    "def list_word_embbed(list_words):\n",
    "    embbed=[word_embbed(w) for w in list_words]\n",
    "    return np.asarray(embbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wv['kesulitan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RES_ID</th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>RESPONSE_CLN</th>\n",
       "      <th>RESPONSE_CLN2</th>\n",
       "      <th>count_word</th>\n",
       "      <th>count_word_cln</th>\n",
       "      <th>count_word_cln2</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_word_length_cln</th>\n",
       "      <th>...</th>\n",
       "      <th>is_layak</th>\n",
       "      <th>is_pakaian</th>\n",
       "      <th>is_konsumen</th>\n",
       "      <th>is_pahala</th>\n",
       "      <th>is_kondisi</th>\n",
       "      <th>is_membutuhkan</th>\n",
       "      <th>is_karena</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>count_topwords</th>\n",
       "      <th>RESPOND_USED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>TRB82</td>\n",
       "      <td>untuk mengurangi penggunan air</td>\n",
       "      <td>0</td>\n",
       "      <td>mengurangi penggunan air</td>\n",
       "      <td>untuk mengurangi penggunan</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>untuk mengurangi penggunan 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TRB29</td>\n",
       "      <td>karena t sebagai upaya untuk membuat produksi ...</td>\n",
       "      <td>1</td>\n",
       "      <td>upaya produksi pakaian beretika</td>\n",
       "      <td>karena sebagai upaya untuk membuat produksi pa...</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6.090909</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>karena sebagai upaya untuk membuat produksi pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>TRB170</td>\n",
       "      <td>mungkin pakaian itu tidak bagus untuk di pakai...</td>\n",
       "      <td>0</td>\n",
       "      <td>pakaian bagus pakai pakaian muat pakai orang</td>\n",
       "      <td>mungkin pakaian tidak bagus untuk pakai lagi m...</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>mungkin pakaian tidak bagus untuk pakai lagi m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>TRB98</td>\n",
       "      <td>karena jika ikhlas menyumangkan sedikit uang k...</td>\n",
       "      <td>0</td>\n",
       "      <td>ikhlas menyumangkan uang anak yatim panti asuh...</td>\n",
       "      <td>karena jika ikhlas menyumangkan sedikit uang k...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>6.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>karena jika ikhlas menyumangkan sedikit uang k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>TRB237</td>\n",
       "      <td>karna harga yang ditawarkan tidak sebanding de...</td>\n",
       "      <td>0</td>\n",
       "      <td>harga ditawarkan sebanding kualitas kaus konsu...</td>\n",
       "      <td>karna harga yang ditawarkan tidak sebanding de...</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>karna harga yang ditawarkan tidak sebanding de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>TRB163</td>\n",
       "      <td>karana dengan menyumbang kita bisa membuat pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>menyumbang produksi pakain beretika</td>\n",
       "      <td>karana dengan menyumbang kita bisa membuat pro...</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6.454545</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>karana dengan menyumbang kita bisa membuat pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>TRB128</td>\n",
       "      <td>karena konsumen ingin berupaya untuk membuat p...</td>\n",
       "      <td>0</td>\n",
       "      <td>konsumen berupaya produksi menjad beretika</td>\n",
       "      <td>karena konsumen ingin berupaya untuk membuat p...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>karena konsumen ingin berupaya untuk membuat p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>TRB195</td>\n",
       "      <td>karena dengan menyumbang maka akan membuat pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>menyumbang produksi pakaian beretika kondisi k...</td>\n",
       "      <td>karena dengan menyumbang maka akan membuat pro...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>6.388889</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>karena dengan menyumbang maka akan membuat pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>TRB232</td>\n",
       "      <td>karena masyarakat menginginkan pakaian yang be...</td>\n",
       "      <td>1</td>\n",
       "      <td>masyarakat pakaian beretika upah kerja layak</td>\n",
       "      <td>karena masyarakat menginginkan pakaian yang be...</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>karena masyarakat menginginkan pakaian yang be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>TRB293</td>\n",
       "      <td>karna menyumbang itu adalah hal positif dan me...</td>\n",
       "      <td>0</td>\n",
       "      <td>menyumbang positif amal ibadah</td>\n",
       "      <td>karna menyumbang adalah positif mendapatkan am...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>karna menyumbang adalah positif mendapatkan am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     RES_ID                                           RESPONSE  LABEL  \\\n",
       "81    TRB82                     untuk mengurangi penggunan air      0   \n",
       "28    TRB29  karena t sebagai upaya untuk membuat produksi ...      1   \n",
       "169  TRB170  mungkin pakaian itu tidak bagus untuk di pakai...      0   \n",
       "97    TRB98  karena jika ikhlas menyumangkan sedikit uang k...      0   \n",
       "236  TRB237  karna harga yang ditawarkan tidak sebanding de...      0   \n",
       "162  TRB163  karana dengan menyumbang kita bisa membuat pro...      0   \n",
       "127  TRB128  karena konsumen ingin berupaya untuk membuat p...      0   \n",
       "194  TRB195  karena dengan menyumbang maka akan membuat pro...      1   \n",
       "231  TRB232  karena masyarakat menginginkan pakaian yang be...      1   \n",
       "292  TRB293  karna menyumbang itu adalah hal positif dan me...      0   \n",
       "\n",
       "                                          RESPONSE_CLN  \\\n",
       "81                            mengurangi penggunan air   \n",
       "28                     upaya produksi pakaian beretika   \n",
       "169       pakaian bagus pakai pakaian muat pakai orang   \n",
       "97   ikhlas menyumangkan uang anak yatim panti asuh...   \n",
       "236  harga ditawarkan sebanding kualitas kaus konsu...   \n",
       "162                menyumbang produksi pakain beretika   \n",
       "127         konsumen berupaya produksi menjad beretika   \n",
       "194  menyumbang produksi pakaian beretika kondisi k...   \n",
       "231       masyarakat pakaian beretika upah kerja layak   \n",
       "292                     menyumbang positif amal ibadah   \n",
       "\n",
       "                                         RESPONSE_CLN2  count_word  \\\n",
       "81                          untuk mengurangi penggunan           4   \n",
       "28   karena sebagai upaya untuk membuat produksi pa...          11   \n",
       "169  mungkin pakaian tidak bagus untuk pakai lagi m...          20   \n",
       "97   karena jika ikhlas menyumangkan sedikit uang k...          20   \n",
       "236  karna harga yang ditawarkan tidak sebanding de...          30   \n",
       "162  karana dengan menyumbang kita bisa membuat pro...          11   \n",
       "127  karena konsumen ingin berupaya untuk membuat p...          10   \n",
       "194  karena dengan menyumbang maka akan membuat pro...          18   \n",
       "231  karena masyarakat menginginkan pakaian yang be...          14   \n",
       "292  karna menyumbang adalah positif mendapatkan am...          10   \n",
       "\n",
       "     count_word_cln  count_word_cln2  avg_word_length  avg_word_length_cln  \\\n",
       "81                3                3         6.750000             7.333333   \n",
       "28                4               10         6.090909             7.000000   \n",
       "169               7               16         5.100000             5.428571   \n",
       "97                9               19         5.600000             6.222222   \n",
       "236              12               29         5.800000             7.000000   \n",
       "162               4               11         6.454545             8.000000   \n",
       "127               5               10         6.600000             7.600000   \n",
       "194               7               17         6.388889             7.285714   \n",
       "231               6               12         6.357143             6.500000   \n",
       "292               4                7         5.800000             6.750000   \n",
       "\n",
       "     ...  is_layak  is_pakaian  is_konsumen  is_pahala  is_kondisi  \\\n",
       "81   ...         0           0            0          0           0   \n",
       "28   ...         0           1            0          0           0   \n",
       "169  ...         0           1            0          0           0   \n",
       "97   ...         0           0            0          1           0   \n",
       "236  ...         0           0            1          0           0   \n",
       "162  ...         0           0            0          0           0   \n",
       "127  ...         0           0            1          0           0   \n",
       "194  ...         0           1            0          0           1   \n",
       "231  ...         1           1            0          0           0   \n",
       "292  ...         0           0            0          0           0   \n",
       "\n",
       "     is_membutuhkan  is_karena  count_stopwords  count_topwords  \\\n",
       "81                0          0                1               0   \n",
       "28                0          1                6               3   \n",
       "169               0          0               11               3   \n",
       "97                0          1               11               1   \n",
       "236               0          1               17               1   \n",
       "162               0          1                7               3   \n",
       "127               0          1                5               3   \n",
       "194               0          1               11               7   \n",
       "231               0          1                8               4   \n",
       "292               0          1                6               1   \n",
       "\n",
       "                                          RESPOND_USED  \n",
       "81   untuk mengurangi penggunan 0 0 0 0 0 0 0 0 0 0...  \n",
       "28   karena sebagai upaya untuk membuat produksi pa...  \n",
       "169  mungkin pakaian tidak bagus untuk pakai lagi m...  \n",
       "97   karena jika ikhlas menyumangkan sedikit uang k...  \n",
       "236  karna harga yang ditawarkan tidak sebanding de...  \n",
       "162  karana dengan menyumbang kita bisa membuat pro...  \n",
       "127  karena konsumen ingin berupaya untuk membuat p...  \n",
       "194  karena dengan menyumbang maka akan membuat pro...  \n",
       "231  karena masyarakat menginginkan pakaian yang be...  \n",
       "292  karna menyumbang adalah positif mendapatkan am...  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1=[c for c in data_raw.columns if ('is_' in c)|('avg_' in c)|('count_' in c)]\n",
    "col2=['RESPOND_USED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count_word',\n",
       " 'count_word_cln',\n",
       " 'count_word_cln2',\n",
       " 'avg_word_length',\n",
       " 'avg_word_length_cln',\n",
       " 'is_sumbang',\n",
       " 'is_kerja',\n",
       " 'is_upaya',\n",
       " 'is_memilih',\n",
       " 'is_pabrik',\n",
       " 'is_membantu',\n",
       " 'is_orang',\n",
       " 'is_pekerja',\n",
       " 'is_produksi',\n",
       " 'is_menyumbang',\n",
       " 'is_beretika',\n",
       " 'is_layak',\n",
       " 'is_pakaian',\n",
       " 'is_konsumen',\n",
       " 'is_pahala',\n",
       " 'is_kondisi',\n",
       " 'is_membutuhkan',\n",
       " 'is_karena',\n",
       " 'count_stopwords',\n",
       " 'count_topwords']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 31)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split Data\n",
    "data_raw_tr=data_raw.sample(250,random_state=231)\n",
    "data_raw_te=data_raw[~(data_raw.RES_ID.isin(data_raw_tr.RES_ID.unique()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alamhanz/anaconda/envs/word_s/lib/python3.7/site-packages/ipykernel/__main__.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n",
      "/Users/alamhanz/anaconda/envs/word_s/lib/python3.7/site-packages/ipykernel/__main__.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/alamhanz/anaconda/envs/word_s/lib/python3.7/site-packages/ipykernel/__main__.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/Users/alamhanz/anaconda/envs/word_s/lib/python3.7/site-packages/ipykernel/__main__.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/Users/alamhanz/anaconda/envs/word_s/lib/python3.7/site-packages/ipykernel/__main__.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/Users/alamhanz/anaconda/envs/word_s/lib/python3.7/site-packages/ipykernel/__main__.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/Users/alamhanz/anaconda/envs/word_s/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X1_tr=data_raw_tr[col1].as_matrix()\n",
    "X2_tr=np.array([list_word_embbed(i[0].split(' ')) for i in data_raw_tr[col2].as_matrix()])\n",
    "\n",
    "X1_te=data_raw_te[col1].as_matrix()\n",
    "X2_te=np.array([list_word_embbed(i[0].split(' ')) for i in data_raw_te[col2].as_matrix()])\n",
    "\n",
    "X_tr=[(Variable(torch.from_numpy(z1).type('torch.DoubleTensor')),Variable(torch.from_numpy(z2).type('torch.DoubleTensor'))) for z1,z2 in zip(X1_tr,X2_tr)]\n",
    "X_te=[(Variable(torch.from_numpy(z1).type('torch.DoubleTensor')),Variable(torch.from_numpy(z2).type('torch.DoubleTensor'))) for z1,z2 in zip(X1_te,X2_te)]\n",
    "\n",
    "Y_tr=data_raw_tr['LABEL'].as_matrix()\n",
    "Y_te=data_raw_te['LABEL'].as_matrix()\n",
    "\n",
    "Y_tr=Y_tr.reshape(len(Y_tr),1)\n",
    "Y_te=Y_te.reshape(len(Y_te),1)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(Y_tr)\n",
    "\n",
    "Y_tr = encoder.transform(Y_tr)\n",
    "Y_te = encoder.transform(Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 75])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr[0][1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM Example\n",
    "class ModelB(torch.nn.Module):\n",
    "    def __init__(self, input_size1, input_size2, output_size):        \n",
    "        super(ModelB, self).__init__()\n",
    "        self.input_size1=input_size1\n",
    "        self.input_size2=input_size2\n",
    "        \n",
    "        self.softmax = torch.nn.Softmax()\n",
    "        \n",
    "        self.features1 = torch.nn.Sequential(\n",
    "            torch.nn.LSTM(self.input_size1, 150)\n",
    "        )\n",
    "        \n",
    "        self.features2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.input_size2, 50,bias=False),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(50, 25,bias=False),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(25, 5,bias=False),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.features3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(30, 30,bias=False),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(30, 30,bias=False),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(30, 15,bias=False),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(15, 10,bias=False),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(10, 2,bias=False),\n",
    "            torch.nn.Softmax())\n",
    "        \n",
    "        \n",
    "        self.features4 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(150, 50,bias=False),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(50, 50,bias=False),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(50, 25,bias=False),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(25, 25,bias=False),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input1,input2):\n",
    "        torch.manual_seed(193)\n",
    "        # input1=input[1]\n",
    "        # input2=input[0]\n",
    "\n",
    "        input1=input1.view(1,15, -1)\n",
    "        input2=input2.view(1,-1)\n",
    "\n",
    "        x1,h = self.features1(input1)\n",
    "        x1_1=x1[:,-1]\n",
    "        x1 = self.features4(x1_1)\n",
    "        x2 = self.features2(input2)\n",
    "        \n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        \n",
    "        out=torch.cat((x1, x2), 1)\n",
    "        y_pred=self.features3(out)\n",
    "        \n",
    "        return y_pred,'-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_LEN=wv.vector_size\n",
    "\n",
    "model1_B = ModelB(input_size1=EMBEDDING_LEN,\n",
    "                  input_size2=25, \n",
    "                  output_size=1)\n",
    "model1_B=model1_B.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate=0.0007\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.BCELoss()\n",
    "# criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model1_B.parameters(),lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1_A(X_tr[1][1],X_tr[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_tr0, X_tr1, Y_tr0, Y_tr1 = train_test_split(X_tr, Y_tr, test_size=0.15, random_state=113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_tr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49027039 0.50972961]] [[0. 1.]]\n",
      "running loss train 0.6924366904578994\n",
      "running loss test 0.6815489942232543\n",
      "[[0.39736505 0.60263495]] [[0. 1.]]\n",
      "running loss train 0.6748009962292006\n",
      "running loss test 0.6184732678817116\n",
      "[[0.34450988 0.65549012]] [[0. 1.]]\n",
      "running loss train 0.6319281677678042\n",
      "running loss test 0.654693387513263\n",
      "[[0.19825279 0.80174721]] [[0. 1.]]\n",
      "running loss train 0.5841971758166583\n",
      "running loss test 0.5918186694235245\n",
      "[[0.18213609 0.81786391]] [[0. 1.]]\n",
      "running loss train 0.5673429227199828\n",
      "running loss test 0.6089888243305364\n",
      "[[0.17473336 0.82526664]] [[0. 1.]]\n",
      "running loss train 0.5601814834034544\n",
      "running loss test 0.6285444335195104\n",
      "[[0.16019593 0.83980407]] [[0. 1.]]\n",
      "running loss train 0.5526964148886383\n",
      "running loss test 0.6100187370429658\n",
      "[[0.17259021 0.82740979]] [[0. 1.]]\n",
      "running loss train 0.5574886919979232\n",
      "running loss test 0.6263567649504755\n",
      "[[0.16501646 0.83498354]] [[0. 1.]]\n",
      "running loss train 0.5550767969617703\n",
      "running loss test 0.6225784164916837\n",
      "[[0.16185947 0.83814053]] [[0. 1.]]\n",
      "running loss train 0.5436035221653758\n",
      "running loss test 0.6397915106282686\n"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "for epoch in range(epochs):\n",
    "    model1_B.train()\n",
    "    # Converting inputs and labels to Variable\n",
    "    running_loss_train = 0\n",
    "    batch_idx=1\n",
    "    for (data, target) in zip(X_tr,Y_tr):\n",
    "        inputs = data\n",
    "        labels = Variable(torch.from_numpy(target.toarray()))\n",
    "        # labels = Variable(torch.from_numpy(target.toarray()).type('torch.DoubleTensor'))\n",
    "        optimizer.zero_grad()\n",
    "        outputs, hidden = model1_B(inputs[1],inputs[0])\n",
    "        # get loss for the predicted output\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss_train += (loss.item() - running_loss_train) / batch_idx\n",
    "        batch_idx+=1\n",
    "    \n",
    "    model1_B.eval()\n",
    "    batch_idx=1\n",
    "    with torch.no_grad():\n",
    "        running_loss_test = 0\n",
    "        for (data, target) in zip(X_te,Y_te):\n",
    "            inputs_te = data\n",
    "            labels_te = Variable(torch.from_numpy(target.toarray()))\n",
    "            outputs_te, hidden = model1_B(inputs_te[1],inputs_te[0])\n",
    "            loss_te = criterion(outputs_te, labels_te)\n",
    "            running_loss_test += (loss_te.item() - running_loss_test) / batch_idx\n",
    "            batch_idx+=1\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(outputs.data.numpy(),labels.data.numpy())\n",
    "        print(\"running loss train\", running_loss_train)\n",
    "        print(\"running loss test\", running_loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelB(\n",
       "  (softmax): Softmax(dim=None)\n",
       "  (features1): Sequential(\n",
       "    (0): LSTM(75, 150)\n",
       "  )\n",
       "  (features2): Sequential(\n",
       "    (0): Linear(in_features=25, out_features=50, bias=False)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=50, out_features=25, bias=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=25, out_features=5, bias=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (features3): Sequential(\n",
       "    (0): Linear(in_features=30, out_features=30, bias=False)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=30, out_features=30, bias=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=30, out_features=15, bias=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=15, out_features=10, bias=False)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Linear(in_features=10, out_features=2, bias=False)\n",
       "    (9): Softmax(dim=None)\n",
       "  )\n",
       "  (features4): Sequential(\n",
       "    (0): Linear(in_features=150, out_features=50, bias=False)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=50, out_features=50, bias=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=50, out_features=25, bias=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=25, out_features=25, bias=False)\n",
       "    (7): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_B.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_model(model,X,Y):\n",
    "    yt=[]\n",
    "    yp=[]\n",
    "    for (data,y) in zip(X,Y.toarray()):\n",
    "        outputs, hidden = model(data[1],data[0])\n",
    "        yp.append(outputs.data.numpy()[-1][-1])\n",
    "        yt.append(y[-1])\n",
    "\n",
    "    yp=(np.array(yp)>0.4).astype(float).tolist()\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(yt,yp).ravel()\n",
    "    acc=(tn+tp)/(tn+fp+fn+tp)\n",
    "    prec=tp/(tp+fp)\n",
    "    recc=tp/(tp+fn)\n",
    "\n",
    "    print('Accuracy :',acc )\n",
    "    print('Precision :',prec )\n",
    "    print('Recall :',recc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.736\n",
      "Precision : 0.7169811320754716\n",
      "Recall : 0.8444444444444444\n"
     ]
    }
   ],
   "source": [
    "evaluation_model(model1_B,X_tr,Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7090909090909091\n",
      "Precision : 0.7428571428571429\n",
      "Recall : 0.7878787878787878\n"
     ]
    }
   ],
   "source": [
    "evaluation_model(model1_B,X_te,Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1_B, MODEL_PATH+\"20190903_model_B_1.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:word_s]",
   "language": "python",
   "name": "conda-env-word_s-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
